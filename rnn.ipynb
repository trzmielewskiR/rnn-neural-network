{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef8b68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb61f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    with lzma.open(path, mode='rt', encoding='utf-8') as f:\n",
    "        df = pd.read_csv(f, sep='\\t', header=None, names=[\"tag\", \"sentence\"])\n",
    "    return list(zip(df[\"sentence\"], df[\"tag\"]))\n",
    "\n",
    "def load_eval_data(in_path, expected_path):\n",
    "    sentences = Path(in_path).read_text(encoding='utf-8').splitlines()\n",
    "    tags = Path(expected_path).read_text(encoding='utf-8').splitlines()\n",
    "    return list(zip(sentences, tags))\n",
    "\n",
    "train = load_train_data(\"train/train.tsv.xz\")\n",
    "val = load_eval_data(\"dev-0/in.tsv\", \"dev-0/expected.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5db968b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traning set: 945 examples\n",
      "Validation set: 215 examples\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align(data):\n",
    "    output = []\n",
    "    for sentence, tag_seq in data:\n",
    "        words = sentence.strip().split()\n",
    "        tags = tag_seq.strip().split()\n",
    "        if len(words) != len(tags):\n",
    "            continue\n",
    "        output.append(list(zip(words, tags)))\n",
    "    return output\n",
    "\n",
    "train_data = tokenize_and_align(train)\n",
    "val_data = tokenize_and_align(val)\n",
    "\n",
    "print(f\"\\nTraning set: {len(train_data)} examples\")\n",
    "print(f\"Validation set: {len(val_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efbe7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(dataset):\n",
    "    word_counter = Counter()\n",
    "    tag_counter = Counter()\n",
    "\n",
    "    for sentence in dataset:\n",
    "        for word, tag in sentence:\n",
    "            word_counter[word.lower()] += 1\n",
    "            tag_counter[tag] += 1\n",
    "\n",
    "    word2idx = {w: i+2 for i, (w, _) in enumerate(word_counter.most_common())}\n",
    "    word2idx[\"<PAD>\"] = 0\n",
    "    word2idx[\"<UNK>\"] = 1\n",
    "\n",
    "    tag2idx = {t: i for i, t in enumerate(tag_counter)}\n",
    "    idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "    return word2idx, tag2idx, idx2tag\n",
    "\n",
    "word2idx, tag2idx, idx2tag = build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a5eac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data, word2idx, tag2idx, max_len=50):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "        self.tag2idx = tag2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data[idx]\n",
    "        words = [w.lower() for w, _ in sentence]\n",
    "        tags = [t for _, t in sentence]\n",
    "\n",
    "        x = [self.word2idx.get(w, self.word2idx[\"<UNK>\"]) for w in words]\n",
    "        y = [self.tag2idx[t] for t in tags]\n",
    "\n",
    "        pad_len = self.max_len - len(x)\n",
    "        x += [self.word2idx[\"<PAD>\"]] * pad_len\n",
    "        y += [-100] * pad_len  # niech ktos w pytorch to jako wbudowana metode zrobi bo przesada\n",
    "        return torch.tensor(x[:self.max_len]), torch.tensor(y[:self.max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17536a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_data, word2idx, tag2idx)\n",
    "val_dataset = NERDataset(val_data, word2idx, tag2idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8e1f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, emb_dim=100, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim // 2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(emb)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "889a7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BiLSTM_NER(len(word2idx), len(tag2idx)).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55c7b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 46.2019\n",
      "Epoch 2 | Loss: 25.6757\n",
      "Epoch 3 | Loss: 23.1771\n",
      "Epoch 4 | Loss: 21.2837\n",
      "Epoch 5 | Loss: 19.3272\n",
      "Epoch 6 | Loss: 17.4752\n",
      "Epoch 7 | Loss: 15.6517\n",
      "Epoch 8 | Loss: 13.9306\n",
      "Epoch 9 | Loss: 12.2374\n",
      "Epoch 10 | Loss: 10.6850\n",
      "Epoch 11 | Loss: 9.2959\n",
      "Epoch 12 | Loss: 8.0934\n",
      "Epoch 13 | Loss: 7.0023\n",
      "Epoch 14 | Loss: 6.0746\n",
      "Epoch 15 | Loss: 5.2888\n",
      "Epoch 16 | Loss: 4.5763\n",
      "Epoch 17 | Loss: 3.9698\n",
      "Epoch 18 | Loss: 3.4438\n",
      "Epoch 19 | Loss: 2.9841\n",
      "Epoch 20 | Loss: 2.5669\n"
     ]
    }
   ],
   "source": [
    "epoch_number = 20\n",
    "\n",
    "for epoch in range(epoch_number):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        y_batch = y_batch.view(-1)\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a15dc99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n",
    "        labels = y_batch.numpy()\n",
    "\n",
    "        for pred_seq, label_seq in zip(preds, labels):\n",
    "            for p, l in zip(pred_seq, label_seq):\n",
    "                if l != -100:\n",
    "                    all_preds.append(p)\n",
    "                    all_labels.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fb1770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 (macro): 0.6243\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "print(f\"Validation F1 (macro): {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
